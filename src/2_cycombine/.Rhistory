uncorrected <-readRDS(file.path(rds_dir, "uncorrected.RDS"))
# Install cyCombine package from GitHub
devtools::install_github("biosurf/cyCombine")
library(cyCombine)
library(tidyverse)
print('Everything loaded in')
# Directory with FCS files
data_dir <- "/Users/user/Documents/final_stroke_data/flowai_fcs_files_results_qc/"
rds_dir <- "/Users/user/Documents/final_stroke_data/cycombine_rds/"
# Extract markers from panel
panel_file <- paste0("/Users/user/Documents/final_stroke_data/metadata_files/panel_metadata_all_batches.csv") # Can also be .xlsx
metadata_file <- paste0("/Users/user/Documents/final_stroke_data/metadata_files/stroke_impact_metadata_all_batches.csv") # Can also be .xlsx
print('Meta data loaded')
uncorrected <-readRDS(file.path(rds_dir, "uncorrected.RDS"))
uncorrected <-readRDS(file.path(rds_dir, "uncorrected.RDS"))
# Install cyCombine package from GitHub
devtools::install_github("biosurf/cyCombine")
library(cyCombine)
library(tidyverse)
print('Everything loaded in')
# Directory with FCS files
data_dir <- "/Users/user/Documents/final_stroke_data/flowai_fcs_files_results_qc/"
rds_dir <- "/Users/user/Documents/final_stroke_data/cycombine_rds/"
# Extract markers from panel
panel_file <- paste0("/Users/user/Documents/final_stroke_data/metadata_files/panel_metadata_all_batches.csv") # Can also be .xlsx
metadata_file <- paste0("/Users/user/Documents/final_stroke_data/metadata_files/stroke_impact_metadata_all_batches.csv") # Can also be .xlsx
print('Meta data loaded')
# Extract markers of interest
markers <- read.csv(panel_file) %>%
filter(Type != "None") %>%
pull(Antigen)
# Prepare a tibble from directory of FCS files
uncorrected <- prepare_data(
data_dir = data_dir,
metadata = metadata_file,
filename_col = "Filename",
batch_ids = "batch",
condition = "condition",
sample_ids = "Patient_id",
markers = markers,
down_sample = FALSE,
.keep = FALSE,
clean_colnames = FALSE,
panel = panel_file,
down_sample = TRUE,           # Change this
downsample_n = 50000,
panel_channel = "Channel",
panel_antigen = "Antigen",
transform = TRUE)
uncorrected <- prepare_data(
data_dir = data_dir,
metadata = metadata_file,
filename_col = "Filename",
batch_ids = "batch",
condition = "condition",
sample_ids = "Patient_id",
markers = markers,
.keep = FALSE,
clean_colnames = FALSE,
panel = panel_file,
down_sample = TRUE,           # Change this
downsample_n = 50000,
panel_channel = "Channel",
panel_antigen = "Antigen",
transform = TRUE)
# Prepare a tibble from directory of FCS files
uncorrected <- prepare_data(
data_dir = data_dir,
metadata = metadata_file,
filename_col = "Filename",
batch_ids = "batch",
condition = "condition",
sample_ids = "Patient_id",
markers = markers,
.keep = FALSE,
clean_colnames = FALSE,
panel = panel_file,
down_sample = TRUE,           # Change this
panel_channel = "Channel",
panel_antigen = "Antigen",
transform = TRUE)
#uncorrected <-readRDS(file.path(rds_dir, "uncorrected.RDS"))
#print('Uncorrected RDS Made')
gc()
seed_num <- sample(1:100, 1) #Setting a random seed number
corrected <- uncorrected %>% batch_correct(
covar = "condition",
markers = markers,
norm_method = "rank", # "rank" is recommended when combining data with heavy batch effects
seed = seed_num # Recommended to use your own random seed
)
saveRDS(corrected, file.path(rds_dir, "corrected.RDS"))
print('Corrected Tibble made')
gc()
# Re-run clustering on corrected data
labels <- corrected %>%
create_som(markers = markers,
rlen = 10)
uncorrected$label <- corrected$label <- labels
# Evaluate EMD
emd <- evaluate_emd(uncorrected, corrected, cell_col = "label")
# Reduction
emd$reduction
# Violin plot
emd$violin
# Scatter plot
emd$scatter
# Evaluate MAD
mad <- evaluate_mad(uncorrected, corrected, cell_col = "label")
# Score
mad$score
